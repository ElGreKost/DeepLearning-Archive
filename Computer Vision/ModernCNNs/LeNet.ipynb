{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = 'cuda'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class BNLeNet(nn.Module):\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.LazyBatchNorm2d(),\n",
    "            nn.Sigmoid(), nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(), nn.LazyLinear(120), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(84), nn.LazyBatchNorm1d(),\n",
    "            nn.Sigmoid(), nn.LazyLinear(num_classes))\n",
    "\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "    def apply_init(self, inputs, init=None):\n",
    "        self.forward(*inputs)\n",
    "        if init is not None:\n",
    "            self.net.apply(init)\n",
    "\n",
    "def init_cnn(module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a188a284f33549b5b9354128f0c0396c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.5988\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e8e635e9ddb46ebb11a85882b36d132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.4009\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5952c86f61104205b54f0b387714d56c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.3535\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5cea0fdb838442eaca50e5831c04633"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.3270\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dba193a575de4bbe8929b411f3f629de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.3043\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c7e36927bf8461fa5b807c7f5964c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.2922\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f890d92f779840408cf787550615ed5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.2765\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9027280307c401fac378e37496af248"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.2674\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83871d2eede344bb91d4434328909f88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.2572\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1875 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efbe0293365b4b5787575d41d3a38c69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.2472\n"
     ]
    }
   ],
   "source": [
    "model = BNLeNet().to(device)\n",
    "input_data = next(iter(train_loader))[0].to(device)\n",
    "model.apply_init([input_data], init_cnn)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (images, labels) in tqdm(enumerate(train_loader), total=total_step):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average epoch loss\n",
    "    average_loss = epoch_loss / total_step\n",
    "    print(f\"Epoch [{epoch+1}/10], Average Loss: {average_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# here has my first impl so too many useless staff"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def init_cnn(module):  #@save\n",
    "    \"\"\"Initialize weights for CNNs.\"\"\"\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "class LeNet(nn.Module):  #@save\n",
    "    \"\"\"The LeNet-5 model.\"\"\"\n",
    "    def __init__(self, lr=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        # self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16, 120), nn.Sigmoid(),\n",
    "            nn.Linear(120, 84), nn.Sigmoid(),\n",
    "            nn.Linear(84, num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "#\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "#\n",
    "# batch_size = 128\n",
    "#\n",
    "# trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "#\n",
    "# testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "#\n",
    "# classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal','Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal','Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(next(iter(trainloader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(trainloader))\n",
    "\n",
    "fig=plt.figure(figsize=(20,5),facecolor='w')\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(1,10, i+1)\n",
    "    plt.imshow(imgs[i, 0, :, :], vmin=0, vmax=1.0, cmap=cm.gray)\n",
    "    ax.set_title(\"{}\".format(classes_names[labels[i]]), fontsize=15)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig('fashionMNIST_samples.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "dt  = next(iter(trainloader))\n",
    "# Convert the grayscale image to RGB\n",
    "rgb_image = TF.to_pil_image(dt[0].squeeze(), mode='L').convert('RGB')\n",
    "\n",
    "# Plot the RGB image\n",
    "plt.imshow(rgb_image)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(next(dataiter).shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "# model.apply_init(next(iter(trainloader(True)))[0], init_cnn)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        X, y = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LazyLinear(nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_features))\n",
    "        self.lazy = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.lazy:\n",
    "            self.weight.requires_grad = True\n",
    "            self.lazy = False\n",
    "        return x @ self.weight.t()\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class LazyConv2d(nn.Module):\n",
    "    def __init__(self, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(out_channels, 1, kernel_size, kernel_size))\n",
    "        self.lazy = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.lazy:\n",
    "            self.weight.requires_grad = True\n",
    "            self.lazy = False\n",
    "        return F.conv2d(x, self.weight)\n",
    "\n",
    "\n",
    "\n",
    "class LazyLeNet(nn.Module):\n",
    "    def __init(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = LazyConv2d(6, 5)\n",
    "        self.conv2 = LazyConv2d(16, 5)\n",
    "        self.fc1 = LazyLinear(120)\n",
    "        self.fc2 = LazyLinear(84)\n",
    "        self.fc3 = LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 19\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Define the loss function and optimizer\u001B[39;00m\n\u001B[0;32m     18\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m---> 19\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtime\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(time\u001B[38;5;241m.\u001B[39mlocaltime())\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\optim\\adam.py:33\u001B[0m, in \u001B[0;36mAdam.__init__\u001B[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weight_decay value: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(weight_decay))\n\u001B[0;32m     29\u001B[0m defaults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39mbetas, eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m     30\u001B[0m                 weight_decay\u001B[38;5;241m=\u001B[39mweight_decay, amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m     31\u001B[0m                 maximize\u001B[38;5;241m=\u001B[39mmaximize, foreach\u001B[38;5;241m=\u001B[39mforeach, capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m     32\u001B[0m                 differentiable\u001B[38;5;241m=\u001B[39mdifferentiable, fused\u001B[38;5;241m=\u001B[39mfused)\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\optim\\optimizer.py:187\u001B[0m, in \u001B[0;36mOptimizer.__init__\u001B[1;34m(self, params, defaults)\u001B[0m\n\u001B[0;32m    185\u001B[0m param_groups \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(params)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(param_groups) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moptimizer got an empty parameter list\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(param_groups[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    189\u001B[0m     param_groups \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: param_groups}]\n",
      "\u001B[1;31mValueError\u001B[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "# Define the training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "# Initialize the LeNet model\n",
    "model = LazyLeNet().to(device)\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "import time\n",
    "print(time.localtime())\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training loss for every 100 batches\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=7, tm_mday=18, tm_hour=5, tm_min=54, tm_sec=45, tm_wday=1, tm_yday=199, tm_isdst=1)\n",
      "Epoch [1/10], Step [100/938], Loss: 0.6910\n",
      "Epoch [1/10], Step [200/938], Loss: 0.8383\n",
      "Epoch [1/10], Step [300/938], Loss: 0.7747\n",
      "Epoch [1/10], Step [400/938], Loss: 0.4881\n",
      "Epoch [1/10], Step [500/938], Loss: 0.5645\n",
      "Epoch [1/10], Step [600/938], Loss: 0.6745\n",
      "Epoch [1/10], Step [700/938], Loss: 0.4498\n",
      "Epoch [1/10], Step [800/938], Loss: 0.5023\n",
      "Epoch [1/10], Step [900/938], Loss: 0.5302\n",
      "Epoch [2/10], Step [100/938], Loss: 0.6039\n",
      "Epoch [2/10], Step [200/938], Loss: 0.3609\n",
      "Epoch [2/10], Step [300/938], Loss: 0.4716\n",
      "Epoch [2/10], Step [400/938], Loss: 0.3101\n",
      "Epoch [2/10], Step [500/938], Loss: 0.4419\n",
      "Epoch [2/10], Step [600/938], Loss: 0.4262\n",
      "Epoch [2/10], Step [700/938], Loss: 0.4097\n",
      "Epoch [2/10], Step [800/938], Loss: 0.3769\n",
      "Epoch [2/10], Step [900/938], Loss: 0.4123\n",
      "Epoch [3/10], Step [100/938], Loss: 0.2825\n",
      "Epoch [3/10], Step [200/938], Loss: 0.5024\n",
      "Epoch [3/10], Step [300/938], Loss: 0.3788\n",
      "Epoch [3/10], Step [400/938], Loss: 0.3820\n",
      "Epoch [3/10], Step [500/938], Loss: 0.4298\n",
      "Epoch [3/10], Step [600/938], Loss: 0.4761\n",
      "Epoch [3/10], Step [700/938], Loss: 0.3234\n",
      "Epoch [3/10], Step [800/938], Loss: 0.4184\n",
      "Epoch [3/10], Step [900/938], Loss: 0.3316\n",
      "Epoch [4/10], Step [100/938], Loss: 0.2571\n",
      "Epoch [4/10], Step [200/938], Loss: 0.3950\n",
      "Epoch [4/10], Step [300/938], Loss: 0.4834\n",
      "Epoch [4/10], Step [400/938], Loss: 0.2669\n",
      "Epoch [4/10], Step [500/938], Loss: 0.3259\n",
      "Epoch [4/10], Step [600/938], Loss: 0.2734\n",
      "Epoch [4/10], Step [700/938], Loss: 0.4716\n",
      "Epoch [4/10], Step [800/938], Loss: 0.2203\n",
      "Epoch [4/10], Step [900/938], Loss: 0.2877\n",
      "Epoch [5/10], Step [100/938], Loss: 0.4328\n",
      "Epoch [5/10], Step [200/938], Loss: 0.3119\n",
      "Epoch [5/10], Step [300/938], Loss: 0.3341\n",
      "Epoch [5/10], Step [400/938], Loss: 0.1749\n",
      "Epoch [5/10], Step [500/938], Loss: 0.2444\n",
      "Epoch [5/10], Step [600/938], Loss: 0.2009\n",
      "Epoch [5/10], Step [700/938], Loss: 0.2828\n",
      "Epoch [5/10], Step [800/938], Loss: 0.2692\n",
      "Epoch [5/10], Step [900/938], Loss: 0.4290\n",
      "Epoch [6/10], Step [100/938], Loss: 0.2894\n",
      "Epoch [6/10], Step [200/938], Loss: 0.2658\n",
      "Epoch [6/10], Step [300/938], Loss: 0.2940\n",
      "Epoch [6/10], Step [400/938], Loss: 0.1761\n",
      "Epoch [6/10], Step [500/938], Loss: 0.2932\n",
      "Epoch [6/10], Step [600/938], Loss: 0.2615\n",
      "Epoch [6/10], Step [700/938], Loss: 0.1755\n",
      "Epoch [6/10], Step [800/938], Loss: 0.2607\n",
      "Epoch [6/10], Step [900/938], Loss: 0.3544\n",
      "Epoch [7/10], Step [100/938], Loss: 0.5076\n",
      "Epoch [7/10], Step [200/938], Loss: 0.2814\n",
      "Epoch [7/10], Step [300/938], Loss: 0.2902\n",
      "Epoch [7/10], Step [400/938], Loss: 0.2302\n",
      "Epoch [7/10], Step [500/938], Loss: 0.1945\n",
      "Epoch [7/10], Step [600/938], Loss: 0.4326\n",
      "Epoch [7/10], Step [700/938], Loss: 0.3054\n",
      "Epoch [7/10], Step [800/938], Loss: 0.1897\n",
      "Epoch [7/10], Step [900/938], Loss: 0.2907\n",
      "Epoch [8/10], Step [100/938], Loss: 0.2309\n",
      "Epoch [8/10], Step [200/938], Loss: 0.1573\n",
      "Epoch [8/10], Step [300/938], Loss: 0.3414\n",
      "Epoch [8/10], Step [400/938], Loss: 0.1968\n",
      "Epoch [8/10], Step [500/938], Loss: 0.3281\n",
      "Epoch [8/10], Step [600/938], Loss: 0.1499\n",
      "Epoch [8/10], Step [700/938], Loss: 0.3064\n",
      "Epoch [8/10], Step [800/938], Loss: 0.1696\n",
      "Epoch [8/10], Step [900/938], Loss: 0.2372\n",
      "Epoch [9/10], Step [100/938], Loss: 0.1823\n",
      "Epoch [9/10], Step [200/938], Loss: 0.2571\n",
      "Epoch [9/10], Step [300/938], Loss: 0.2958\n",
      "Epoch [9/10], Step [400/938], Loss: 0.1984\n",
      "Epoch [9/10], Step [500/938], Loss: 0.1576\n",
      "Epoch [9/10], Step [600/938], Loss: 0.1868\n",
      "Epoch [9/10], Step [700/938], Loss: 0.1260\n",
      "Epoch [9/10], Step [800/938], Loss: 0.2571\n",
      "Epoch [9/10], Step [900/938], Loss: 0.3514\n",
      "Epoch [10/10], Step [100/938], Loss: 0.1646\n",
      "Epoch [10/10], Step [200/938], Loss: 0.1033\n",
      "Epoch [10/10], Step [300/938], Loss: 0.2357\n",
      "Epoch [10/10], Step [400/938], Loss: 0.1905\n",
      "Epoch [10/10], Step [500/938], Loss: 0.1333\n",
      "Epoch [10/10], Step [600/938], Loss: 0.1314\n",
      "Epoch [10/10], Step [700/938], Loss: 0.2973\n",
      "Epoch [10/10], Step [800/938], Loss: 0.3278\n",
      "Epoch [10/10], Step [900/938], Loss: 0.3747\n",
      "time.struct_time(tm_year=2023, tm_mon=7, tm_mday=18, tm_hour=5, tm_min=57, tm_sec=38, tm_wday=1, tm_yday=199, tm_isdst=1)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 78\u001B[0m\n\u001B[0;32m     76\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m test_loader:\n\u001B[1;32m---> 78\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     79\u001B[0m     _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs\u001B[38;5;241m.\u001B[39mdata, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     80\u001B[0m     total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[1], line 19\u001B[0m, in \u001B[0;36mLeNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 19\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     20\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax_pool2d(x, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the LeNet model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "# Initialize the LeNet model\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "import time\n",
    "print(time.localtime())\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training loss for every 100 batches\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(time.localtime())\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {(100 * correct / total):.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()  # Start time\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move the tensors to the configured device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the epoch loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average epoch loss\n",
    "    average_loss = epoch_loss / total_step\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Calculate the total training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet().to(device)\n",
    "\n",
    "start_time = time.time()\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y = model(images)\n",
    "        loss = criterion(y, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print training loss for every 100 batches\n",
    "\n",
    "    avg_loss = total_loss / total_step\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Calculate the total training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import time\n",
    "\n",
    "# Define the LeNet model\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, device='cuda'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5, device='cuda'),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the training parameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the LeNet model and move it to the GPU\n",
    "model = LeNet().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_step = len(train_loader)\n",
    "start_time = time.time()  # Start time\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Move the tensors to the configured device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "        model.zero_grad()\n",
    "        y = model(images)\n",
    "        loss = criterion(y, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the epoch loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average epoch loss\n",
    "    average_loss = epoch_loss / total_step\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}\")\n",
    "\n",
    "# Calculate the total training time\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Move the tensors to the configured device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {(100 * correct / total):.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "[(x, k) for x, k in zip(X,K)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2: 100%|| 20/20 [00:02<00:00,  9.03it/s]\n",
      "2: 100%|| 20/20 [00:02<00:00,  9.02it/s]\n",
      "2: 100%|| 20/20 [00:02<00:00,  9.07it/s]\n",
      "2:   0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.3\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2\u001B[39m\u001B[38;5;124m'\u001B[39m, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m----> 6\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "for i in range(10):\n",
    "    time.sleep(0.3)\n",
    "    for j in tqdm(range(20), desc='2', leave=True):\n",
    "        time.sleep(0.1)\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
