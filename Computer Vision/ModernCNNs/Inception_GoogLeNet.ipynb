{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    # c1 --c4 are the number of output channels for each branch\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.b1_1 = nn.LazyConv2d(c1, 1)\n",
    "\n",
    "        self.b2_1 = nn.LazyConv2d(c2[0], 1)\n",
    "        self.b2_2 = nn.LazyConv2d(c2[1], 3, 1, 1)\n",
    "\n",
    "        self.b3_1 = nn.LazyConv2d(c3[0], 1)\n",
    "        self.b3_2 = nn.LazyConv2d(c3[1], 5, 1, 2)\n",
    "\n",
    "        self.b4_1 = nn.MaxPool2d(3, 1, 1)\n",
    "        self.b4_2 = nn.LazyConv2d(c4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = F.relu(self.b1_1(x))\n",
    "        b2 = F.relu(self.b2_2(F.relu(self.b2_1(x))))\n",
    "        b3 = F.relu(self.b3_2(F.relu(self.b3_1(x))))\n",
    "        b4 = F.relu(self.b4_2(self.b4_1(x)))\n",
    "        return torch.cat((b1,b2,b3,b4), dim=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, 7, 2, 3), nn.ReLU(), nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "    def b2(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, 1), nn.ReLU(),\n",
    "            nn. LazyConv2d(192, 3, 1, 1), nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "\n",
    "    def b3(self):\n",
    "        return nn.Sequential(\n",
    "            Inception(64, (96, 128), (16, 32), 32),\n",
    "            Inception(128, (128, 192), (32, 96), 64),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "\n",
    "        )\n",
    "    def b4(self):\n",
    "        return nn.Sequential(\n",
    "            Inception(192, (96, 208), (16, 48), 64),\n",
    "            Inception(160, (112, 224), (24, 64), 64),\n",
    "            Inception(128, (128, 256), (24, 64), 64),\n",
    "            Inception(112, (144, 288), (32, 64), 64),\n",
    "            Inception(256, (160, 320), (32, 128), 128),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "    def b5(self):\n",
    "        return nn.Sequential(\n",
    "            Inception(256, (160, 320), (32, 128), 128),\n",
    "            Inception(384, (192, 384), (48, 128), 128),\n",
    "            nn.AdaptiveAvgPool2d((1,1)), nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self.b1(), self.b2(), self.b3(), self.b4(),\n",
    "            self.b5(), nn.LazyLinear(num_classes))\n",
    "        self.net.apply(init_cnn)\n",
    "\n",
    "    def apply_init(self, inputs, init=None):\n",
    "        self.forward(*inputs)\n",
    "        if init is not None:\n",
    "            self.net.apply(init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "\n",
    "def init_cnn(module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f08dae7f7fe45f49e16798b5dc847f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.7983\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acd7762ae2f0435193c27907bf449eb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.3494\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e6be4b747c4489091c0a5fa4f68f02d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.2831\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d514d275b6ae4219b056b5f0c8c30949"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.2463\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bf54b4923fa4850ad9f38071a3aeeaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.2225\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "963fd3d4d58f432784c67dcfb03f39a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.2049\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c82c208132b43aea09649dbf343cfd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.1905\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7863ba8ecdae4ec9ac85385c958c87cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.1754\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21a2f299efa74cdf92c433fc965cc425"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.1614\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ca069ff6ac04bc79347d0259de40e27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.1534\n"
     ]
    }
   ],
   "source": [
    "import algos\n",
    "train_loader, _ = algos.load_mnist()\n",
    "model = algos.fit(GoogLeNet(), train_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m     test_loader \u001B[38;5;241m=\u001B[39m DataLoader(dataset\u001B[38;5;241m=\u001B[39mtest_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_loader, test_loader\n\u001B[1;32m---> 11\u001B[0m train_loader, test_loader \u001B[38;5;241m=\u001B[39m \u001B[43mload_mnist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m, in \u001B[0;36mload_mnist\u001B[1;34m(batch_size, resize)\u001B[0m\n\u001B[0;32m      2\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m128\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Load the FashionMNIST dataset\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m transform \u001B[38;5;241m=\u001B[39m \u001B[43mtransforms\u001B[49m\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mToTensor(), transforms\u001B[38;5;241m.\u001B[39mNormalize((\u001B[38;5;241m0.5\u001B[39m,), (\u001B[38;5;241m0.5\u001B[39m,)), transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m96\u001B[39m,\u001B[38;5;241m96\u001B[39m))])\n\u001B[0;32m      6\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m FashionMNIST(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtransform, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m FashionMNIST(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtransform)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "def load_mnist(batch_size = 128, resize = (96,96)):\n",
    "    batch_size = 128\n",
    "\n",
    "    # Load the FashionMNIST dataset\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)), transforms.Resize((96,96))])\n",
    "    train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "train_loader, test_loader = load_mnist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cafc4bbc54f14d0997c2abf42d034b26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13658dbd99d84027b89e6dd4a0ae6c09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.3778\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "336216651cbd4777aa57a4579017af20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.3034\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b45b62fccc6436488a91dce6ef3aa99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.2672\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4b2f996f217453f8ee056342f212261"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.2421\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10eb79f7715149a0b8469ee78909f6bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.2243\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4362583079fd44f9983c915ca870ce57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.2057\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e5df57002fe457cad328ca37720bd97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.1882\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c8a7401727142b0b9a4d8a9fd8af0e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.1786\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9417120f22042c3990fa89d241b4ea7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.1704\n"
     ]
    }
   ],
   "source": [
    "model = GoogLeNet().to(device)\n",
    "input_data = next(iter(train_loader))[0].to(device)\n",
    "model.apply_init([input_data], init_cnn)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (images, labels) in tqdm(enumerate(train_loader), total=total_step):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Print average epoch loss\n",
    "    average_loss = epoch_loss / total_step\n",
    "    print(f\"Epoch [{epoch+1}/10], Average Loss: {average_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
