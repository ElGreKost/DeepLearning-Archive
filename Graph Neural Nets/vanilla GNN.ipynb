{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Including Node Features with Vanilla Neural Networks\n",
    "\n",
    "In this chapter, we’ll cover the following topics:\n",
    "- Introducing graph datasets **Cora** $\\cdot$ **Facebook Page-Page**\n",
    "- Classifying nodes with vanilla neural networks\n",
    "- Classifying nodes with vanilla graph neural networks\n",
    "\n",
    "Visualization tools:\n",
    "- yEd Live\n",
    "- Gephi"
   ],
   "id": "8deab5f3edc2e7ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Datasets\n",
    "**Cora** for node classification\n",
    "It represents a network of 2,708 publications, where each connection is a reference. Each publication is described as a binary vector of 1,433 unique words, where 0 and 1 indicate the absence or presence of the corresponding word, respectively.  \n",
    "This representation is also called a binary bag of words in natural language processing. Our goal is to classify each node into one of seven categories.\n",
    "\n",
    "!<img src=\"images/cora.png\" width=500>"
   ],
   "id": "819c139beeeb5f9b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:37.086316Z",
     "start_time": "2024-09-11T09:09:37.055008Z"
    }
   },
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:37.308957Z",
     "start_time": "2024-09-11T09:09:37.298352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dataset[0]\n",
    "print(f'Dataset: {dataset}')\n",
    "print('---------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ],
   "id": "35116ae7ce3f39fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "---------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:37.406325Z",
     "start_time": "2024-09-11T09:09:37.361449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Graph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ],
   "id": "557eead6cc774e74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:38.844412Z",
     "start_time": "2024-09-11T09:09:37.407311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get Tabular representation of cora dataset without topological information\n",
    "import pandas as pd \n",
    "df_x = pd.DataFrame(data.x.numpy())\n",
    "df_x['label'] = pd.DataFrame(data.y)\n",
    "df_x"
   ],
   "id": "2e48d802082f922",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "2703  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
       "2704  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2705  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2706  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      1427  1428  1429  1430  1431  1432  label  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "...    ...   ...   ...   ...   ...   ...    ...  \n",
       "2703   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2704   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2705   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2706   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2707   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[2708 rows x 1434 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 1434 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Facebook Page-Page**  \n",
    "In this dataset, each of the 22,470 nodes represents an official Facebook page. Pages are connected when there are mutual likes between them. Node features (128-dim vectors) are created from textual descriptions written by the owners of these pages.  \n",
    "Our goal is to classify each node into one of four categories: politicians, companies, television shows, and governmental organizations.\n",
    "\n",
    "!<img src=\"images/facebook-page-page.png\" width=500>"
   ],
   "id": "f6fd7ffa3c551a04"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Three major differences with Cora:\n",
    "\n",
    "- The number of nodes is much higher (2,708 versus 22,470)\n",
    "- The dimensionality of the node features decreased dramatically (from 1,433 to 128)\n",
    "- The goal is to classify each node into four categories instead of seven (which is easier since there are fewer options)"
   ],
   "id": "1fe1c00f3b0d99ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:38.897455Z",
     "start_time": "2024-09-11T09:09:38.848386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.datasets import FacebookPagePage\n",
    "dataset = FacebookPagePage(root='.')\n",
    "data = dataset[0]"
   ],
   "id": "c092db436888569e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\io\\fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:38.912869Z",
     "start_time": "2024-09-11T09:09:38.898265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Dataset: {dataset}')\n",
    "print('-----------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ],
   "id": "a49d6d3718f0834",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FacebookPagePage()\n",
      "-----------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 22470\n",
      "Number of features: 128\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:39.262119Z",
     "start_time": "2024-09-11T09:09:38.915888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ],
   "id": "33d47e45f9220ff1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: True\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: True\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:39.341215Z",
     "start_time": "2024-09-11T09:09:39.266665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd \n",
    "df_x = pd.DataFrame(data.x.numpy())\n",
    "df_x['label'] = pd.DataFrame(data.y)\n",
    "df_x"
   ],
   "id": "d84c246b3f82cb73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "1     -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "2     -0.262576 -0.265053 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "3     -0.246378 -0.276483 -0.241991 -0.299327 -0.299159 -0.270681 -0.307051   \n",
       "4     -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "22465 -0.262576 -0.276483 -0.262350 -0.296955 -0.299159 -0.270681 -0.307757   \n",
       "22466 -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "22467 -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307757   \n",
       "22468 -0.262576 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.307668   \n",
       "22469 -0.232275 -0.276483 -0.262350 -0.299327 -0.299159 -0.270681 -0.293968   \n",
       "\n",
       "              7        8         9  ...       119       120       121  \\\n",
       "0     -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.284379   \n",
       "1     -0.269733 -0.25101 -0.308343  ... -0.234818 -0.223700 -0.284379   \n",
       "2     -0.210461 -0.25101  3.222161  ... -0.273229 -0.223700 -0.284379   \n",
       "3     -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.265534   \n",
       "4     -0.269733 -0.25101 -0.308343  ... -0.273229 -0.175312 -0.272613   \n",
       "...         ...      ...       ...  ...       ...       ...       ...   \n",
       "22465 -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.284379   \n",
       "22466 -0.269733 -0.25101 -0.308343  ... -0.273229 -0.221643 -0.284379   \n",
       "22467 -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.284379   \n",
       "22468 -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.284379   \n",
       "22469 -0.269733 -0.25101 -0.308343  ... -0.273229 -0.223700 -0.284379   \n",
       "\n",
       "            122       123       124       125       126       127  label  \n",
       "0     -0.224216 -0.209509 -0.255755 -0.215140 -0.375903 -0.223836      0  \n",
       "1     -0.197935 -0.147256 -0.255755 -0.215140 -0.364134 -0.128634      2  \n",
       "2     -0.224216 -0.209509 -0.255755 -0.215140 -0.375903 -0.223836      1  \n",
       "3     -0.080353 -0.209509 -0.250560 -0.180260 -0.375903 -0.223836      2  \n",
       "4     -0.224216 -0.181153 -0.255755 -0.215140 -0.370639 -0.223836      3  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "22465 -0.224216 -0.209509 -0.255755 -0.196685 -0.370115 -0.223836      3  \n",
       "22466 -0.224216 -0.209509 -0.255755 -0.215140 -0.375903 -0.223836      1  \n",
       "22467 -0.224216 -0.146793 -0.255755 -0.180389 -0.372097 -0.222613      2  \n",
       "22468 -0.224216 -0.209509 -0.252456 -0.215140 -0.375903 -0.218148      1  \n",
       "22469 -0.224216 -0.147672 -0.255755 -0.195858 -0.375903 -0.221275      0  \n",
       "\n",
       "[22470 rows x 129 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.234818</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.197935</td>\n",
       "      <td>-0.147256</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.364134</td>\n",
       "      <td>-0.128634</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.265053</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.210461</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>3.222161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.246378</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.241991</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307051</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.265534</td>\n",
       "      <td>-0.080353</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.250560</td>\n",
       "      <td>-0.180260</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.175312</td>\n",
       "      <td>-0.272613</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.181153</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.370639</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22465</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.296955</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.196685</td>\n",
       "      <td>-0.370115</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22466</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.221643</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.223836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22467</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307757</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.146793</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.180389</td>\n",
       "      <td>-0.372097</td>\n",
       "      <td>-0.222613</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22468</th>\n",
       "      <td>-0.262576</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.307668</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.209509</td>\n",
       "      <td>-0.252456</td>\n",
       "      <td>-0.215140</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.218148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22469</th>\n",
       "      <td>-0.232275</td>\n",
       "      <td>-0.276483</td>\n",
       "      <td>-0.262350</td>\n",
       "      <td>-0.299327</td>\n",
       "      <td>-0.299159</td>\n",
       "      <td>-0.270681</td>\n",
       "      <td>-0.293968</td>\n",
       "      <td>-0.269733</td>\n",
       "      <td>-0.25101</td>\n",
       "      <td>-0.308343</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273229</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.284379</td>\n",
       "      <td>-0.224216</td>\n",
       "      <td>-0.147672</td>\n",
       "      <td>-0.255755</td>\n",
       "      <td>-0.195858</td>\n",
       "      <td>-0.375903</td>\n",
       "      <td>-0.221275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22470 rows × 129 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Unlike Cora, Facebook Page-Page doesn’t have training, evaluation, and test masks by default. \n",
    "- We can arbitrarily create masks with the range() function:\n",
    "- Or use torch_geometric.transforms as T to randomly calculate masks when the dataset is loaded."
   ],
   "id": "368b02899cd92bf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:39.356915Z",
     "start_time": "2024-09-11T09:09:39.341215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)"
   ],
   "id": "eed21ef3d0b4cf2c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Vanilla MLP for node cls",
   "id": "4a1fc7c03b78ca4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:39.388132Z",
     "start_time": "2024-09-11T09:09:39.356915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(dim_in, dim_h)\n",
    "        self.linear2 = torch.nn.Linear(dim_h, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        \n",
    "        self.train()\n",
    "        for epoch in tqdm(range(epochs + 1), desc='Epoch'):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    " \n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "    \n",
    "def accuracy(y_pred, y_true):\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ],
   "id": "3672da4755cc9ac2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:44.371172Z",
     "start_time": "2024-09-11T09:09:39.388132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Facebook Page Page\n",
    "from torch_geometric.datasets import FacebookPagePage\n",
    "dataset = FacebookPagePage(root='.')\n",
    "data = dataset[0]\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)\n",
    "\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "mlp.fit(data, epochs=100)\n",
    "# Test\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
   ],
   "id": "f49544ad1a475394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\io\\fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/101 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cb4d19e774e4a6e8e0f88a31a03cacc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.393 | Train Acc: 23.78% | Val Loss: 1.39 | Val Acc: 24.66%\n",
      "Epoch  20 | Train Loss: 0.657 | Train Acc: 73.77% | Val Loss: 0.67 | Val Acc: 72.84%\n",
      "Epoch  40 | Train Loss: 0.576 | Train Acc: 77.16% | Val Loss: 0.62 | Val Acc: 74.89%\n",
      "Epoch  60 | Train Loss: 0.548 | Train Acc: 78.47% | Val Loss: 0.60 | Val Acc: 75.49%\n",
      "Epoch  80 | Train Loss: 0.531 | Train Acc: 79.02% | Val Loss: 0.59 | Val Acc: 76.24%\n",
      "Epoch 100 | Train Loss: 0.518 | Train Acc: 79.50% | Val Loss: 0.59 | Val Acc: 75.84%\n",
      "\n",
      "MLP test accuracy: 75.17%\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:45.771450Z",
     "start_time": "2024-09-11T09:09:44.373207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cora\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "mlp.fit(data, epochs=100)\n",
    "# Test\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
   ],
   "id": "75fbba71018b9f37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epoch:   0%|          | 0/101 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db6319bc7e2f4785ac3342fee1518965"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 1.960 | Train Acc: 14.29% | Val Loss: 1.96 | Val Acc: 7.20%\n",
      "Epoch  20 | Train Loss: 0.107 | Train Acc: 100.00% | Val Loss: 1.42 | Val Acc: 50.80%\n",
      "Epoch  40 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 1.43 | Val Acc: 51.20%\n",
      "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.40 | Val Acc: 52.60%\n",
      "Epoch  80 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.35 | Val Acc: 53.60%\n",
      "Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.33 | Val Acc: 53.00%\n",
      "\n",
      "MLP test accuracy: 54.70%\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Classifying nodes with vanilla graph neural networks"
   ],
   "id": "ecc1b4216b1f6b13"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Instead of directly introducing well-known GNN architectures, let's try to build our own model to understand the thought process behind GNNs. First, we need to go back to the definition of a simple linear layer.\n",
    "\n",
    "A basic neural network layer corresponds to a linear transformation:\n",
    "\n",
    "$$\n",
    "h_A = x_A W^T\n",
    "$$\n",
    "\n",
    "where $x_A$ is the input vector of node $A$, and $W$ is the weight matrix. In PyTorch, this equation can be implemented with the `torch.mm()` function, or with the `nn.Linear` class that adds other parameters such as biases.\n",
    "\n",
    "With our graph datasets, the input vectors are node features. It means that nodes are completely separate from each other. This is not enough to capture a good understanding of the graph: like a pixel in an image, the context of a node is essential to understand it. If you look at a group of pixels instead of a single one, you can recognize edges, patterns, and so on. Likewise, to understand a node, you need to look at its neighborhood.\n",
    "\n",
    "Let's call $\\mathcal{N}_A$ the set of neighbors of node $A$. Our graph linear layer can be written as follows:\n",
    "\n",
    "$$\n",
    "h_A = \\sum_{i \\in \\mathcal{N}_A} x_i W^T\n",
    "$$\n",
    "\n",
    "You can imagine several variants of this equation. For instance, we could have a weight matrix $W_1$ dedicated to the central node, and another one $W_2$ for the neighbors. Note that we cannot have a weight matrix per neighbor, as this number can change from node to node.\n",
    "\n",
    "We're talking about neural networks, so we can't apply the previous equation to each node. Instead, we perform matrix multiplications that are much more efficient. For instance, the equation of the linear layer can be rewritten as:\n",
    "\n",
    "$$\n",
    "H = X W^T\n",
    "$$\n",
    "\n",
    "where $X$ is the input matrix.\n",
    "\n",
    "In our case, the adjacency matrix $A$ contains the connections between every node in the graph. Multiplying the input matrix by this adjacency matrix will directly sum up the neighboring node features. We can add **self loops** to the adjacency matrix so that the central node is also considered in this operation. We call this updated adjacency matrix $\\tilde{A} = A + I$. Our graph linear layer can be rewritten as follows:\n",
    "\n",
    "$$\n",
    "H = \\tilde{A}^T X W^T\n",
    "$$\n",
    "\n",
    "Let's test this layer by implementing it in PyTorch Geometric. We'll then be able to use it as a regular layer to build a GNN.\n"
   ],
   "id": "f1d01143d0bc9c21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:45.795509Z",
     "start_time": "2024-09-11T09:09:45.773933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VanillaGNNLayer(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(VanillaGNNLayer, self).__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
    "        \n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x)\n",
    "        x = torch.sparse.mm(adjacency, x)\n",
    "        return x"
   ],
   "id": "72350cc5321ae3f3",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:45.811853Z",
     "start_time": "2024-09-11T09:09:45.799992Z"
    }
   },
   "cell_type": "code",
   "source": "dataset, data.edge_index.shape",
   "id": "5b3899443e310cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Cora(), torch.Size([2, 10556]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:09:45.869374Z",
     "start_time": "2024-09-11T09:09:45.811853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "adjacency = to_dense_adj(data.edge_index)[0] # take the first one because we don't have batch dim. otherwise we would have to add eye to every batch I guess...\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency"
   ],
   "id": "22a2bf912afd0c49",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:12:08.670314Z",
     "start_time": "2024-09-11T09:12:08.638524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "class VanillaGNN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super(VanillaGNN, self).__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h)\n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out)\n",
    "        \n",
    "    def forward(self, x, adjacency):\n",
    "        h = self.gnn1(x, adjacency)\n",
    "        h = torch.relu(h)\n",
    "        h = self.gnn2(h, adjacency)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "    \n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in tqdm(range(epochs+1), desc='Epochs'):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data.x, adjacency)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % 20 == 0:\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    \n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, adjacency)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc"
   ],
   "id": "a4a121c54bebfa12",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:12:14.935961Z",
     "start_time": "2024-09-11T09:12:09.040740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cora\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "\n",
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "gnn.fit(data, epochs=100)\n",
    "print(f'\\nGNN test accuracy: {gnn.test(data)*100:.2f}%')"
   ],
   "id": "b7c4f49abe2e395",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\io\\fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epochs:   0%|          | 0/101 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7741e1528cae497da1fc03d855a5e08f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 2.035 | Train Acc: 21.43% | Val Loss: 2.08 | Val Acc: 18.20%\n",
      "Epoch  20 | Train Loss: 0.060 | Train Acc: 100.00% | Val Loss: 1.75 | Val Acc: 72.20%\n",
      "Epoch  40 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 2.56 | Val Acc: 73.60%\n",
      "Epoch  60 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.82 | Val Acc: 73.60%\n",
      "Epoch  80 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.70 | Val Acc: 74.00%\n",
      "Epoch 100 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 2.56 | Val Acc: 74.40%\n",
      "\n",
      "GNN test accuracy: 75.20%\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-11T09:17:28.195240Z",
     "start_time": "2024-09-11T09:12:16.548123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Facebook Page Page\n",
    "from torch_geometric.datasets import FacebookPagePage\n",
    "dataset = FacebookPagePage(root='.')\n",
    "data = dataset[0]\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)\n",
    "\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "\n",
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "gnn.fit(data, epochs=100)\n",
    "print(f'\\nGNN test accuracy: {gnn.test(data)*100:.2f}%')"
   ],
   "id": "72aac10512605418",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "C:\\Users\\kosti\\anaconda3\\envs\\llr_env\\lib\\site-packages\\torch_geometric\\io\\fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=128, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Epochs:   0%|          | 0/101 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9681164b9d54e8d8da26784b78f35aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Train Loss: 97.520 | Train Acc: 24.02% | Val Loss: 89.24 | Val Acc: 25.81%\n",
      "Epoch  20 | Train Loss: 5.117 | Train Acc: 80.79% | Val Loss: 3.49 | Val Acc: 81.64%\n",
      "Epoch  40 | Train Loss: 2.818 | Train Acc: 81.01% | Val Loss: 1.93 | Val Acc: 82.04%\n",
      "Epoch  60 | Train Loss: 1.531 | Train Acc: 82.76% | Val Loss: 1.32 | Val Acc: 83.49%\n",
      "Epoch  80 | Train Loss: 0.860 | Train Acc: 82.36% | Val Loss: 0.78 | Val Acc: 82.64%\n",
      "Epoch 100 | Train Loss: 0.672 | Train Acc: 84.00% | Val Loss: 0.65 | Val Acc: 83.64%\n",
      "\n",
      "GNN test accuracy: 83.80%\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "dataset = FacebookPagePage(root=\".\")\n",
    "data = dataset[0]\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)\n",
    "\n",
    "# Adjacency matrix\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency\n",
    "\n",
    "# MLP\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "mlp.fit(data, epochs=100)\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%\\n')\n",
    "\n",
    "# GCN\n",
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "gnn.fit(data, epochs=100)\n",
    "acc = gnn.test(data)\n",
    "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
   ],
   "id": "4254871bec27f34c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
