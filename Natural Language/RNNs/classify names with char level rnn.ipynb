{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-01T20:35:59.261610Z",
     "start_time": "2024-11-01T20:35:59.248785Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "desired_path = \"C:\\\\Users\\\\kosti\\\\OneDrive - Εθνικό Μετσόβιο Πολυτεχνείο\\\\ΣΗΜΜΥ_2024_2025\\\\Αναγνώριση Προτύπων\\\\1ο Εργαστήριο\\\\torch_tutorials\"\n",
    "os.chdir(desired_path)\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti\\OneDrive - Εθνικό Μετσόβιο Πολυτεχνείο\\ΣΗΜΜΥ_2024_2025\\Αναγνώριση Προτύπων\\1ο Εργαστήριο\\torch_tutorials\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:37:16.246523Z",
     "start_time": "2024-11-01T20:37:16.240735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from io import open \n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('./data/names/*.txt'))"
   ],
   "id": "c3a44f4bacf1a2d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/names\\\\Arabic.txt', './data/names\\\\Chinese.txt', './data/names\\\\Czech.txt', './data/names\\\\Dutch.txt', './data/names\\\\English.txt', './data/names\\\\French.txt', './data/names\\\\German.txt', './data/names\\\\Greek.txt', './data/names\\\\Irish.txt', './data/names\\\\Italian.txt', './data/names\\\\Japanese.txt', './data/names\\\\Korean.txt', './data/names\\\\Polish.txt', './data/names\\\\Portuguese.txt', './data/names\\\\Russian.txt', './data/names\\\\Scottish.txt', './data/names\\\\Spanish.txt', './data/names\\\\Vietnamese.txt']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:39:16.310995Z",
     "start_time": "2024-11-01T20:39:16.302110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))"
   ],
   "id": "e2fc6ff0dbd1caaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:40:31.962866Z",
     "start_time": "2024-11-01T20:40:31.902037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('./data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "    \n",
    "n_categories = len(all_categories)"
   ],
   "id": "83fa0c6b1e697d20",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:40:57.495815Z",
     "start_time": "2024-11-01T20:40:57.490672Z"
    }
   },
   "cell_type": "code",
   "source": "print(category_lines['Italian'][:5])",
   "id": "44cdca3c94cfc332",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:42:57.096200Z",
     "start_time": "2024-11-01T20:42:51.067581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ],
   "id": "795c194803d9b931",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:55:16.576847Z",
     "start_time": "2024-11-01T20:55:16.553646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.U = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.W= nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.V = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        a = self.U(input) + self.W(hidden)\n",
    "        hidden = F.tanh(a)\n",
    "        output = self.V(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "    \n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n"
   ],
   "id": "a4a5be68ef4de3b0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:55:42.411869Z",
     "start_time": "2024-11-01T20:55:42.351636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = letterToTensor('A')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "output, next_hidden = rnn(input, hidden)"
   ],
   "id": "bcf095197e1fdfb6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:56:26.140373Z",
     "start_time": "2024-11-01T20:56:26.131455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input = lineToTensor('Albert')\n",
    "hidden = torch.zeros(1, n_hidden)\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)"
   ],
   "id": "9e70765dee6029fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.8839, -2.9062, -2.9500, -2.7771, -2.9307, -2.9703, -2.8588, -2.8797,\n",
      "         -2.9757, -2.7710, -2.9078, -2.7282, -2.9240, -2.8237, -2.9245, -2.9096,\n",
      "         -2.9768, -2.9777]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:57:55.144674Z",
     "start_time": "2024-11-01T20:57:55.136227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    print(top_n, top_i)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ],
   "id": "2058502ce4b2f511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7282]], grad_fn=<TopkBackward0>) tensor([[11]])\n",
      "('Korean', 11)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T20:58:44.839392Z",
     "start_time": "2024-11-01T20:58:44.827626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ],
   "id": "347dcd0ffe70da3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Irish / line = Rhys\n",
      "category = English / line = Main\n",
      "category = Scottish / line = Hunter\n",
      "category = Portuguese / line = Ribeiro\n",
      "category = Arabic / line = Shalhoub\n",
      "category = Vietnamese / line = Vuu\n",
      "category = French / line = Leveque\n",
      "category = Italian / line = Goretti\n",
      "category = Dutch / line = Pander\n",
      "category = Vietnamese / line = Huynh\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T21:08:01.659670Z",
     "start_time": "2024-11-01T21:08:01.654302Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.NLLLoss() # -logits[y]",
   "id": "3fad1dbff47385e3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T21:08:01.833931Z",
     "start_time": "2024-11-01T21:08:01.827241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 0.005 # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()"
   ],
   "id": "518ed376b8aa6d87",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-01T21:11:12.254615Z",
     "start_time": "2024-11-01T21:08:01.978007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print ``iter`` number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ],
   "id": "7d9cff7050c224be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0061]], grad_fn=<TopkBackward0>) tensor([[14]])\n",
      "5000 5% (0m 9s) 2.0061 Shalashilin / Russian ✓\n",
      "tensor([[-0.7612]], grad_fn=<TopkBackward0>) tensor([[0]])\n",
      "10000 10% (0m 18s) 0.7612 Safar / Arabic ✓\n",
      "tensor([[-1.3413]], grad_fn=<TopkBackward0>) tensor([[8]])\n",
      "15000 15% (0m 27s) 1.8114 Tahan / Irish ✗ (Arabic)\n",
      "tensor([[-0.0632]], grad_fn=<TopkBackward0>) tensor([[7]])\n",
      "20000 20% (0m 37s) 0.0632 Garofalis / Greek ✓\n",
      "tensor([[-0.8592]], grad_fn=<TopkBackward0>) tensor([[9]])\n",
      "25000 25% (0m 46s) 2.3682 Elizondo / Italian ✗ (Spanish)\n",
      "tensor([[-0.1765]], grad_fn=<TopkBackward0>) tensor([[0]])\n",
      "30000 30% (0m 55s) 0.1765 Daher / Arabic ✓\n",
      "tensor([[-1.7392]], grad_fn=<TopkBackward0>) tensor([[6]])\n",
      "35000 35% (1m 5s) 2.3607 Patrick / German ✗ (Irish)\n",
      "tensor([[-0.5846]], grad_fn=<TopkBackward0>) tensor([[2]])\n",
      "40000 40% (1m 16s) 0.5846 Pavlicka / Czech ✓\n",
      "tensor([[-0.0122]], grad_fn=<TopkBackward0>) tensor([[14]])\n",
      "45000 45% (1m 26s) 0.0122 Lezhepekov / Russian ✓\n",
      "tensor([[-1.1352]], grad_fn=<TopkBackward0>) tensor([[6]])\n",
      "50000 50% (1m 35s) 1.1352 Schubert / German ✓\n",
      "tensor([[-0.6083]], grad_fn=<TopkBackward0>) tensor([[13]])\n",
      "55000 55% (1m 45s) 1.6431 Panders / Portuguese ✗ (Dutch)\n",
      "tensor([[-0.0219]], grad_fn=<TopkBackward0>) tensor([[12]])\n",
      "60000 60% (1m 54s) 0.0219 Rudawski / Polish ✓\n",
      "tensor([[-0.1439]], grad_fn=<TopkBackward0>) tensor([[9]])\n",
      "65000 65% (2m 3s) 0.1439 Bicchieri / Italian ✓\n",
      "tensor([[-0.6053]], grad_fn=<TopkBackward0>) tensor([[15]])\n",
      "70000 70% (2m 12s) 2.5913 Kalb / Scottish ✗ (Arabic)\n",
      "tensor([[-1.0715]], grad_fn=<TopkBackward0>) tensor([[4]])\n",
      "75000 75% (2m 22s) 2.3805 Russell / English ✗ (Scottish)\n",
      "tensor([[-1.4763]], grad_fn=<TopkBackward0>) tensor([[3]])\n",
      "80000 80% (2m 31s) 1.4763 Rumpade / Dutch ✓\n",
      "tensor([[-0.7339]], grad_fn=<TopkBackward0>) tensor([[10]])\n",
      "85000 85% (2m 41s) 0.7339 Taguchi / Japanese ✓\n",
      "tensor([[-0.7737]], grad_fn=<TopkBackward0>) tensor([[16]])\n",
      "90000 90% (2m 50s) 0.7737 Gallo / Spanish ✓\n",
      "tensor([[-0.2303]], grad_fn=<TopkBackward0>) tensor([[15]])\n",
      "95000 95% (3m 0s) 0.2303 Young / Scottish ✓\n",
      "tensor([[-0.5100]], grad_fn=<TopkBackward0>) tensor([[0]])\n",
      "100000 100% (3m 10s) 3.9320 Samson / Arabic ✗ (French)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ],
   "id": "4c118f6d3f4ad05d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
